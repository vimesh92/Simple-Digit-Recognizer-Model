{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train.label\n",
    "X=train.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation\n",
    "X_1= X/255\n",
    "\n",
    "test_1= test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (28000, 784))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape,test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_1).reshape(42000,28,28,1)\n",
    "\n",
    "X_test = np.array(test_1).reshape(28000,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size = (4,4),input_shape=(28,28,1),activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten()) #flattening the image after convo and pooling \n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10,activation='softmax')) #multiclass softmax\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='accuracy',patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 2/25\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 3/25\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 4/25\n",
      "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 5/25\n",
      "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 6/25\n",
      "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 7/25\n",
      "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 8/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 9/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 10/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 11/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 12/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 13/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 14/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 15/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 16/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 17/25\n",
      "1313/1313 [==============================] - 15s 11ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 18/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 19/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 5.1566e-04 - accuracy: 0.9999\n",
      "Epoch 20/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 4.2556e-04 - accuracy: 0.9999\n",
      "Epoch 21/25\n",
      "1313/1313 [==============================] - 14s 11ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 22/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 9.3994e-04 - accuracy: 0.9997\n",
      "Epoch 23/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 24/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 25/25\n",
      "1313/1313 [==============================] - 14s 10ms/step - loss: 2.7929e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d3ed12c6c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_cat,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Label'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('vk_submission_three.csv',index=False) #0.98742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = C:\\Users\\IT\\Downloads\\digit-recognizer\\1\n",
      "\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\IT\\Downloads\\digit-recognizer\\1\\assets\n",
      "\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "MODEL_DIR = os.getcwd()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal: <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "NumPy array info:\n",
      "<class 'numpy.ndarray'>\n",
      "type: float32\n",
      "shape: (28, 28, 3)\n",
      "converting NumPy array: <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "# load the image\n",
    "img = load_img('new_test_/2.png')\n",
    "print(\"Orignal:\" ,type(img))\n",
    "\n",
    "img=img.resize((28, 28)) #converting to 28*28\n",
    "# convert to numpy array\n",
    "img_array = img_to_array(img)\n",
    "print(\"NumPy array info:\") \n",
    "print(type(img_array))    \n",
    "\n",
    "print(\"type:\",img_array.dtype)\n",
    "print(\"shape:\",img_array.shape)\n",
    "# convert back to image\n",
    "\n",
    "img_pil = array_to_img(img_array)\n",
    "print(\"converting NumPy array:\",type(img_pil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d40d0b5cc8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
